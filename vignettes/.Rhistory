?gridExtra::grid.arrange
?maids::get_pd
?maids::plot_pd
library(maids)
data+mtpl_be
data(mtpl_be)
var <- power
tibble::tibble(sort(unique(data[, var])))
var <- 'power'
tibble::tibble(sort(unique(data[, var])))
data <- mtpl_be
tibble::tibble(sort(unique(data[, var])))
tibble::tibble(min(data[, var]):max(data[, var]))
data(mtpl_fr)
data <- mtpl_fr
var <- 'popdens'
tibble::tibble(min(data[, var]):max(data[, var]))
tibble::tibble(sort(unique(data[, var])))
1,607/27000
1.607/27000
1607/27000
get_grid <- function(var, data) {
if (! var %in% names(data)) stop('The specified variable could not be found in the supplied data.')
# Integer variable
if ('integer' %in% class(data[, var])) {
if (length(sort(unique(data[, var]))) > 0.5 * length(min(data[, var]):max(data[, var]))) return(tibble::tibble(min(data[, var]):max(data[, var])) %>% setNames(var))
return(tibble::tibble(sort(unique(data[, var]))) %>% setNames(var))
}
# Factor variable
if ('factor' %in% class(data[, var])) return(tibble::tibble(factor(levels(data[, var]), ordered = is.ordered(data[, var]))) %>% setNames(var))
# Numeric variable
if ('numeric' %in% class(data[, var])) return(tibble::tibble(seq(min(data[, var]), max(data[, var]), length.out = 100)) %>% setNames(var))
stop('Unsupported variable type. Only integers, numerics and factors are handled by this function.')
}
get_grid(mtpl_be, 'power')
get_grid('power',mtpl_be)
library(magrittr)
get_grid('power',mtpl_be)
get_grid('popdens',mtpl_fr)
library(maids)
ordr <- which(sapply(pd[c('x1', 'x2')], function(x) class(x)[1]) == 'ordered')
getOption('browser')
which(c(T,F,F,F,T,T))
?which
exp(-3.032025)
1.5 * 0.0482179
warnings()
library(maids)
data('mtpl_be')
library(gbm)
set.seed(54321)
gbm_be <- gbm(nclaims ~ offset(log(expo)) + ageph + power + bm + agec + coverage + fuel + sex + fleet + use,
data = mtpl_be, distribution = 'poisson', shrinkage = 0.01, n.trees = 500, interaction.depth = 3)
c(gbm_be$var.names, 'bm_agec', 'ageph_power', 'power_bm', 'power_agec')
fx_vars_be <- gbm_be %>% insights(vars = c(gbm_be$var.names, 'bm_agec', 'ageph_power', 'power_bm', 'power_agec'),
data = mtpl_be,
interactions = 'user',
pred_fun = gbm_fun)
library(magrittr)
gbm_fun <- function(object, newdata) mean(predict(object, newdata, n.trees = object$n.trees, type = 'response'))
fx_vars_be <- gbm_be %>% insights(vars = c(gbm_be$var.names, 'bm_agec', 'ageph_power', 'power_bm', 'power_agec'),
data = mtpl_be,
interactions = 'user',
pred_fun = gbm_fun)
warnings()
fx_vars_be
fx_vars <- fx_vars_be
data <- mtpl_be
target <- 'nclaims'
nfolds <- 5
strat_vars <- c('nclaims', 'expo')
glm_par <- alist(family = poisson(link = 'log'),
offset = log(expo))
err_fun <- poi_dev
lambdas <- lambda_grid(fx_vars)
lambdas
set.seed(5678)
# Create the fold indicator via (stratified) sampling
data <- data %>% dplyr::sample_n(size = nrow(.), replace = FALSE) %>%
dplyr::arrange(!!! rlang::syms(strat_vars)) %>%
dplyr::mutate(fold = rep_len(seq_len(nfolds), nrow(.)))
data
# Iterate over the lambda grid
for (l in seq_len(nrow(lambdas))) {
print(l)
# Segmentation for current lambda values
data_segm <- maids::segmentation(fx_vars, data = data, lambda = ifelse(grepl('_', lapply(fx_vars, comment)),
lambdas[[l, 'intr']], lambdas[[l, 'main']]))
# Feature selection (only keep those with >1 group) and determine the GLM formula
slct_feat <- names(which(unlist(lapply(data_segm[, grepl('_$', names(data_segm))], function(x) length(unique(x)) > 1))))
glm_par[['formula']] <- as.formula(paste(target, '~', paste(c(1, slct_feat), collapse = ' + ')))
# Calculate the validation errors
val_err <- rep(NA, nfolds)
for (f in seq_len(nfolds)) {
# Fit surrogate GLM on the training fold
glm_fit <- maids::surrogate(dplyr::filter(data_segm, fold != f), glm_par)
# Get validation fold and calculate the prediction error
v_data <- maids::rm_lvls(glm_fit, dplyr::filter(data_segm, fold == f))
y_pred <- predict(glm_fit, newdata = v_data, type = 'response')
y_true <- dplyr::pull(v_data, target)
w_case <- v_data[[deparse(glm_fit$call$weights)]]
val_err[f] <- do.call(err_fun, setNames(lapply(names(formals(err_fun)), function(x) eval(as.name(x))), names(formals(err_fun))))
}
print(val_err)
}
l <- 10
# Segmentation for current lambda values
data_segm <- maids::segmentation(fx_vars, data = data, lambda = ifelse(grepl('_', lapply(fx_vars, comment)),
lambdas[[l, 'intr']], lambdas[[l, 'main']]))
# Feature selection (only keep those with >1 group) and determine the GLM formula
slct_feat <- names(which(unlist(lapply(data_segm[, grepl('_$', names(data_segm))], function(x) length(unique(x)) > 1))))
glm_par[['formula']] <- as.formula(paste(target, '~', paste(c(1, slct_feat), collapse = ' + ')))
slct_feat
# Calculate the validation errors
val_err <- rep(NA, nfolds)
f <- 1
# Fit surrogate GLM on the training fold
glm_fit <- maids::surrogate(dplyr::filter(data_segm, fold != f), glm_par)
# Get validation fold and calculate the prediction error
v_data <- maids::rm_lvls(glm_fit, dplyr::filter(data_segm, fold == f))
y_pred <- predict(glm_fit, newdata = v_data, type = 'response')
y_true <- dplyr::pull(v_data, target)
w_case <- v_data[[deparse(glm_fit$call$weights)]]
val_err[f] <- do.call(err_fun, setNames(lapply(names(formals(err_fun)), function(x) eval(as.name(x))), names(formals(err_fun))))
f <- 2
# Fit surrogate GLM on the training fold
glm_fit <- maids::surrogate(dplyr::filter(data_segm, fold != f), glm_par)
# Get validation fold and calculate the prediction error
v_data <- maids::rm_lvls(glm_fit, dplyr::filter(data_segm, fold == f))
y_pred <- predict(glm_fit, newdata = v_data, type = 'response')
y_true <- dplyr::pull(v_data, target)
w_case <- v_data[[deparse(glm_fit$call$weights)]]
val_err[f] <- do.call(err_fun, setNames(lapply(names(formals(err_fun)), function(x) eval(as.name(x))), names(formals(err_fun))))
f <- 3
# Fit surrogate GLM on the training fold
glm_fit <- maids::surrogate(dplyr::filter(data_segm, fold != f), glm_par)
# Get validation fold and calculate the prediction error
v_data <- maids::rm_lvls(glm_fit, dplyr::filter(data_segm, fold == f))
y_pred <- predict(glm_fit, newdata = v_data, type = 'response')
y_true <- dplyr::pull(v_data, target)
w_case <- v_data[[deparse(glm_fit$call$weights)]]
val_err[f] <- do.call(err_fun, setNames(lapply(names(formals(err_fun)), function(x) eval(as.name(x))), names(formals(err_fun))))
str(data_segm)
str(dplyr::filter(data_segm, fold != f))
slct_feat
data_segm %>% dplyr::summarise_all(dplyr::n_distinct())
data_segm %>% dplyr::summarise_all(~dplyr::n_distinct())
data_segm %>% dplyr::summarise_all(~dplyr::n_distinct(.))
dplyr::filter(data_segm, fold != f) %>% dplyr::summarise_all(~dplyr::n_distinct(.))
dplyr::filter(data_segm, fold == f) %>% dplyr::summarise_all(~dplyr::n_distinct(.))
glm_par[['formula']]
l <- 10
# Segmentation for current lambda values
data_segm <- maids::segmentation(fx_vars, data = data, lambda = ifelse(grepl('_', lapply(fx_vars, comment)),
lambdas[[l, 'intr']], lambdas[[l, 'main']]))
data_segm
# Get training fold
trn_data <- dplyr::filter(data_segm, fold != f)
trn_data
# Feature selection (only keep those with >1 group) and determine the GLM formula
slct_feat <- names(which(unlist(lapply(data_segm[, grepl('_$', names(data_segm))], function(x) length(unique(x)) > 1))))
slct_feat
glm_par[['formula']] <- as.formula(paste(target, '~', paste(c(1, slct_feat), collapse = ' + ')))
glm_par
# Fit surrogate GLM on the training fold
glm_fit <- maids::surrogate(trn_data, glm_par)
# Get training fold
trn_data <- dplyr::filter(data_segm, fold != f)
# Feature selection (only keep those with >1 group) and determine the GLM formula
slct_feat <- names(which(unlist(lapply(trn_data[, grepl('_$', names(trn_data))], function(x) length(unique(x)) > 1))))
glm_par[['formula']] <- as.formula(paste(target, '~', paste(c(1, slct_feat), collapse = ' + ')))
glm_par
# Fit surrogate GLM on the training fold
glm_fit <- maids::surrogate(trn_data, glm_par)
glm_fit
# Get validation fold and calculate the prediction error
val_data <- maids::rm_lvls(glm_fit, dplyr::filter(data_segm, fold == f))
y_pred <- predict(glm_fit, newdata = val_data, type = 'response')
y_true <- dplyr::pull(val_data, target)
w_case <- val_data[[deparse(glm_fit$call$weights)]]
val_err[f] <- do.call(err_fun, setNames(lapply(names(formals(err_fun)), function(x) eval(as.name(x))), names(formals(err_fun))))
val_err
lambdas
lambda_grid
library(maids)
lambda_grid
lambda_grid <- function(fx_vars, lambda_range = as.vector(outer(seq(1, 10, 0.1), 10^(-5:3)))) {
# Split the main and interaction effects
vars <- unlist(lapply(fx_vars, comment))
vars_main <- vars[! grepl('_', vars)]
vars_intr <- vars[grepl('_', vars)]
# Get lambdas that result in unique grouping for main effects
if (length(vars_main) > 0) {
grid_main <- tibble::tibble(lambda_main = lambda_range)
for (v in vars_main) {
grid_main <- grid_main %>% dplyr::mutate(!!v := purrr::map2_int(lambda_range, v, function(x, y) optimal_ngroups(fx_vars[[y]], x)))
}
grid_main <- grid_main %>% dplyr::distinct(!!! rlang::syms(setdiff(names(grid_main), 'lambda_main')), .keep_all = TRUE)
}
# Get lambdas that result in unique grouping for interaction effects
if (length(vars_intr) > 0) {
grid_intr <- tibble::tibble(lambda_intr = lambda_range)
for (v in vars_intr) {
grid_intr <- grid_intr %>% dplyr::mutate(!!v := purrr::map2_int(lambda_range, v, function(x, y) optimal_ngroups(fx_vars[[y]], x)))
}
grid_intr <- grid_intr %>% dplyr::distinct(!!! rlang::syms(setdiff(names(grid_intr), 'lambda_intr')), .keep_all = TRUE)
}
# Output the (combined) grid
if (length(vars_main) > 0 & length(vars_intr) > 0) {
return(tidyr::expand_grid(lambda_main = grid_main$lambda_main, lambda_intr = grid_intr$lambda_intr) %>%
dplyr::left_join(grid_main, by = 'lambda_main') %>%
dplyr::left_join(grid_intr, by = 'lambda_intr'))
}
if (length(vars_main) > 0) return(grid_main)
if (length(vars_intr) > 0) return(grid_intr)
}
lambda_grid
fx_vars
lambdas <- lambda_grid(fx_vars)
lambdas
fx_vars_be
fx_vars <- fx_vars_be
data <- mtpl_be
target <- 'nclaims'
nfolds <- 5
strat_vars <- c('nclaims', 'expo')
glm_par <- alist(family = poisson(link = 'log'),
offset = log(expo))
err_fun <- poi_dev
set.seed(5678)
# Create the fold indicator via (stratified) sampling
data <- data %>% dplyr::sample_n(size = nrow(.), replace = FALSE) %>%
dplyr::arrange(!!! rlang::syms(strat_vars)) %>%
dplyr::mutate(fold = rep_len(seq_len(nfolds), nrow(.)))
data
seq_len(length(fx_vars))
i <- 1
fx_var <- fx_vars[[i]]
l <- 1
var <- fx_var %>% comment
fx_var <- fx_vars[[i]]
fx_var
lambdas[l, var]
lambdas[[l, var]]
fx_grp <- fx_var %>% group_pd(ngroups = lambdas[[l, var]])
data_segm <- data
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
data_segm
str(data_segm)
data_segm <- data
for (i in seq_len(length(fx_vars))) {
var <- fx_var %>% comment
fx_var <- fx_vars[[i]]
fx_grp <- fx_var %>% group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
data
data_segm <- data
data_segm
for (i in seq_len(length(fx_vars))) {
fx_var <- fx_vars[[i]]
var <- fx_var %>% comment
fx_grp <- fx_var %>% group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
data_segm
data
data_segm <- data
for (i in seq_len(length(fx_vars))) {
fx_var <- fx_vars[[i]]
var <- fx_var %>% comment
fx_grp <- fx_var %>% group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
# Segmentation for current lambda values
data_segm1 <- maids::segmentation(fx_vars, data = data, lambda = ifelse(grepl('_', lapply(fx_vars, comment)),
lambdas[[l, 'intr']], lambdas[[l, 'main']]))
grepl('_', lapply(fx_vars, comment))
# Segmentation for current lambda values
data_segm1 <- maids::segmentation(fx_vars, data = data, lambda = ifelse(grepl('_', lapply(fx_vars, comment)),
lambdas[[l, 'lambda_intr']], lambdas[[l, 'lambda_main']]))
data_segm == data_segm1
all(data_segm == data_segm1)
tmp <- proc.time()
data_segm <- data
for (i in seq_len(length(fx_vars))) {
fx_var <- fx_vars[[i]]
var <- fx_var %>% comment
fx_grp <- fx_var %>% group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
proc.time() - tmp
tmp <- proc.time()
data_segm <- data
for (i in seq_len(length(fx_vars))) {
fx_var <- fx_vars[[i]]
var <- fx_var %>% comment
fx_grp <- fx_var %>% group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
proc.time() - tmp
tmp <- proc.time()
data_segm <- data
for (i in seq_len(length(fx_vars))) {
fx_var <- fx_vars[[i]]
var <- fx_var %>% comment
fx_grp <- fx_var %>% group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
proc.time() - tmp
tmp <- proc.time()
data_segm <- data
for (i in seq_len(length(fx_vars))) {
fx_var <- fx_vars[[i]]
var <- fx_var %>% comment
fx_grp <- fx_var %>% group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
proc.time() - tmp
tmp <- proc.time()
data_segm <- data
for (i in seq_len(length(fx_vars))) {
fx_var <- fx_vars[[i]]
var <- fx_var %>% comment
fx_grp <- fx_var %>% group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
proc.time() - tmp
tmp <- proc.time()
data_segm1 <- maids::segmentation(fx_vars, data = data, lambda = ifelse(grepl('_', lapply(fx_vars, comment)),
lambdas[[l, 'lambda_intr']], lambdas[[l, 'lambda_main']]))
proc.time() - tmp
tmp <- proc.time()
data_segm1 <- maids::segmentation(fx_vars, data = data, lambda = ifelse(grepl('_', lapply(fx_vars, comment)),
lambdas[[l, 'lambda_intr']], lambdas[[l, 'lambda_main']]))
proc.time() - tmp
tmp <- proc.time()
data_segm1 <- maids::segmentation(fx_vars, data = data, lambda = ifelse(grepl('_', lapply(fx_vars, comment)),
lambdas[[l, 'lambda_intr']], lambdas[[l, 'lambda_main']]))
proc.time() - tmp
tmp <- proc.time()
data_segm1 <- maids::segmentation(fx_vars, data = data, lambda = ifelse(grepl('_', lapply(fx_vars, comment)),
lambdas[[l, 'lambda_intr']], lambdas[[l, 'lambda_main']]))
proc.time() - tmp
8*400
8*400/60
data_segm <- data
for (i in seq_len(length(fx_vars))) {
fx_var <- fx_vars[[i]]
var <- fx_var %>% comment
fx_grp <- fx_var %>% group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
data_segm
fx_vars <- fx_vars_be
data <- mtpl_be
target <- 'nclaims'
nfolds <- 5
strat_vars <- c('nclaims', 'expo')
glm_par <- alist(family = poisson(link = 'log'),
offset = log(expo))
err_fun <- poi_dev
set.seed(5678)
# Create the fold indicator via (stratified) sampling
data <- data %>% dplyr::sample_n(size = nrow(.), replace = FALSE) %>%
dplyr::arrange(!!! rlang::syms(strat_vars)) %>%
dplyr::mutate(fold = rep_len(seq_len(nfolds), nrow(.)))
# Iterate over the lambda grid
for (l in 1:10) {
print(l)
data_segm <- data
for (i in seq_len(length(fx_vars))) {
fx_var <- fx_vars[[i]]
var <- fx_var %>% comment
fx_grp <- fx_var %>% maids::group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
# Calculate the validation errors
val_err <- rep(NA, nfolds)
for (f in seq_len(nfolds)) {
# Get training fold
trn_data <- dplyr::filter(data_segm, fold != f)
# Feature selection (only keep those with >1 group) and determine the GLM formula
slct_feat <- names(which(unlist(lapply(trn_data[, grepl('_$', names(trn_data))], function(x) length(unique(x)) > 1))))
glm_par[['formula']] <- as.formula(paste(target, '~', paste(c(1, slct_feat), collapse = ' + ')))
# Fit surrogate GLM on the training fold
glm_fit <- maids::surrogate(trn_data, glm_par)
# Get validation fold and calculate the prediction error
val_data <- maids::rm_lvls(glm_fit, dplyr::filter(data_segm, fold == f))
y_pred <- predict(glm_fit, newdata = val_data, type = 'response')
y_true <- dplyr::pull(val_data, target)
w_case <- val_data[[deparse(glm_fit$call$weights)]]
val_err[f] <- do.call(err_fun, setNames(lapply(names(formals(err_fun)), function(x) eval(as.name(x))), names(formals(err_fun))))
}
print(val_err)
}
# Iterate over the lambda grid
1 <- 1
# Iterate over the lambda grid
l <- 1
f <- 4
data_segm <- data
for (i in seq_len(length(fx_vars))) {
fx_var <- fx_vars[[i]]
var <- fx_var %>% comment
fx_grp <- fx_var %>% maids::group_pd(ngroups = lambdas[[l, var]])
data_segm <- data_segm %>% dplyr::left_join(fx_grp[c(paste0('x', if (grepl('_', var)) 1:2), 'xgrp')],
by = setNames(paste0('x', if (grepl('_', var)) 1:2), unlist(strsplit(var, '_')))) %>%
dplyr::mutate(xgrp = relevel(as.factor(xgrp), ref =  (fx_grp %>% dplyr::arrange(-wgrp) %>% dplyr::pull(xgrp))[1])) %>%
dplyr::rename(!!paste0(var, '_') := xgrp)
}
data_segm
lambdas
# Get training fold
trn_data <- dplyr::filter(data_segm, fold != f)
# Feature selection (only keep those with >1 group) and determine the GLM formula
slct_feat <- names(which(unlist(lapply(trn_data[, grepl('_$', names(trn_data))], function(x) length(unique(x)) > 1))))
glm_par[['formula']] <- as.formula(paste(target, '~', paste(c(1, slct_feat), collapse = ' + ')))
glm_par
# Fit surrogate GLM on the training fold
glm_fit <- maids::surrogate(trn_data, glm_par)
glm_fit
# Get validation fold and calculate the prediction error
val_data <- maids::rm_lvls(glm_fit, dplyr::filter(data_segm, fold == f))
sum(is.na(val_data))
val_data
str(val_data)
is.na(val_data)
View(val_data)
y_pred <- predict(glm_fit, newdata = val_data, type = 'response')
y_true <- dplyr::pull(val_data, target)
w_case <- val_data[[deparse(glm_fit$call$weights)]]
y_pred
y_true
w_case
err_fun
sum(is.na(y_pred))
sum(is.na(y_true))
sum(is.nan(y_true))
sum(is.nan(y_pred))
length(y_pred[!is.na(y_pred)])
sum(dpois(y_true, y_pred, log = TRUE) - dpois(y_true, y_true, log = TRUE), na.rm = TRUE)
-2*sum(dpois(y_true, y_pred, log = TRUE) - dpois(y_true, y_true, log = TRUE), na.rm = TRUE)
